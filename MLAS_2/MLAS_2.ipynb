{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o test_set.zip https://zenodo.org/records/1327317/files/test_set.zip?download=1 -o test_set_pixel_size.csv https://zenodo.org/records/1327317/files/test_set_pixel_size.csv?download=1 -o training_set.zip https://zenodo.org/records/1327317/files/training_set.zip?download=1 -o training_set_pixel_size_and_HC.csv https://zenodo.org/records/1327317/files/training_set_pixel_size_and_HC.csv?download=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import tqdm\n",
    "import cv2\n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from timeit import default_timer as timer\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, List\n",
    "import torch.nn.functional as f\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed.\n"
     ]
    }
   ],
   "source": [
    "# Path to the zip file\n",
    "zip_file_path = r'C:/Users/Asus/.vscode/VSC/ML in Med/test_set.zip'\n",
    "# Directory to extract the contents to\n",
    "extract_to_dir = r'C:/Users\\Asus/.vscode/VSC/ML in Med/'\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(extract_to_dir):\n",
    "    os.makedirs(extract_to_dir)\n",
    "# Open the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Extract all contents into the specified directory\n",
    "    zip_ref.extractall(extract_to_dir)\n",
    "\n",
    "print(\"Extraction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, link):\n",
    "        self.link = link\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = cv2.imread(self.link + f\"{index:03d}\"+\"_HC.png\", cv2.IMREAD_GRAYSCALE)\n",
    "        anno = cv2.imread(self.link + f\"{index:03d}\"+\"_HC_Annotation.png\", cv2.IMREAD_GRAYSCALE)\n",
    "        target_height, target_width = 540, 800\n",
    "\n",
    "        if img.shape[0] > target_height:\n",
    "            img = img[:target_height, :]\n",
    "            ano = ano[:target_height, :]\n",
    "        if img.shape[1] > target_width:\n",
    "            img = img[:, :target_width]\n",
    "            ano = ano[:, :target_width]\n",
    "        if img.shape[0] < target_height or img.shape[1] < target_width:\n",
    "            new_img = np.zeros((target_height, target_width))\n",
    "            new_ano = np.zeros((target_height, target_width))\n",
    "            new_img[:img.shape[0], :img.shape[1]] = img\n",
    "            new_ano[:img.shape[0], :img.shape[1]] = ano\n",
    "            img, ano = new_img, new_ano\n",
    "            \n",
    "        img = torch.FloatTensor(img).unsqueeze(0)\n",
    "        mask = np.zeros((548, 804))\n",
    "        anno = np.array(anno, np.uint8)\n",
    "        contours, _ = cv2.findContours(anno, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        ellipse = cv2.fitEllipse(contours[0])\n",
    "        mask = cv2.ellipse(mask, ellipse, (255,255,255), -1)\n",
    "        mask = (mask / 255).astype(int)\n",
    "        mask = torch.FloatTensor(mask).unsqueeze(0)\n",
    "        \n",
    "        return img, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=(96, 94)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.in_block_2 = nn.Sequential(\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.in_block_3 = nn.Sequential(\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.in_block_4 = nn.Sequential(\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(256, 512, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.in_bottle_neck = nn.Sequential(\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(512, 1024, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 1024, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(1024, 512, 2, 2)\n",
    "        )\n",
    "        \n",
    "        self.out_block_4 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 512, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, 2, 2)\n",
    "        )\n",
    "        \n",
    "        self.out_block_3 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 2, 2)\n",
    "        )\n",
    "        \n",
    "        self.out_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 2, 2)\n",
    "        )\n",
    "        \n",
    "        self.out_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 1, 1),\n",
    "            nn.Conv2d(2, 1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        in_1 = self.in_block_1(data)\n",
    "        in_2 = self.in_block_2(in_1)\n",
    "        in_3 = self.in_block_3(in_2)\n",
    "        in_4 = self.in_block_4(in_3)\n",
    "            \n",
    "        out_4 = self.in_bottle_neck(in_4)\n",
    "        x_4, y_4 = out_4.shape[-2], out_4.shape[-1]\n",
    "        out_4 = torch.cat([in_4[:, :, in_4.shape[-2] // 2-x_4 // 2:in_4.shape[-2] // 2 - x_4 // 2 + x_4, in_4.shape[-1] // 2 - y_4 // 2:in_4.shape[-1] // 2 - y_4 // 2 + y_4], out_4], dim=1)\n",
    "            \n",
    "        out_3 = self.out_block_4(out_4)\n",
    "        x_3, y_3 = out_3.shape[-2], out_3.shape[-1]\n",
    "        out_3 = torch.cat([in_3[:, :, in_3.shape[-2] // 2 - x_3 // 2:in_3.shape[-2] // 2 - x_3 // 2 + x_3, in_3.shape[-1] // 2 - y_3 // 2:in_3.shape[-1] // 2 - y_3 // 2 + y_3], out_3], dim=1)\n",
    "            \n",
    "        out_2 = self.out_block_3(out_3)\n",
    "        x_2, y_2 = out_2.shape[-2], out_2.shape[-1]\n",
    "        out_2 = torch.cat([in_2[:, :, in_2.shape[-2] // 2 - x_2 // 2:in_2.shape[-2] // 2 - x_2 // 2 + x_2, in_2.shape[-1] // 2 - y_2 // 2:in_2.shape[-1] // 2 - y_2 // 2 + y_2], out_2], dim=1)\n",
    "            \n",
    "        out_1 = self.out_block_2(out_2)\n",
    "        x_1, y_1 = out_1.shape[-2], out_1.shape[-1]\n",
    "        out_1 = torch.cat([in_1[:, :, in_1.shape[-2] // 2 - x_1 // 2:in_1.shape[-2] // 2 - x_1 // 2 + x_1, in_1.shape[-1] // 2 - y_1 // 2:in_1.shape[-1] // 2 - y_1 // 2 + y_1], out_1], dim=1)\n",
    "            \n",
    "        output = self.out_block_1(out_1)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = CustomDataset(r'C:/Users/Asus/.vscode/VSC/ML in Med/training_set/')\n",
    "training_loader = DataLoader(training_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Unet().to(device)\n",
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_pred, y_true):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(data_loader: torch.utils.data.DataLoader, model: torch.nn.Module,\n",
    "               loss_fn: torch.nn.Module, optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn, device: torch.device = device):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # Send data to GPU\n",
    "        X, y = X.to(device), y.to(device).squeeze(1)\n",
    "\n",
    "        y_pred = model(X)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        \n",
    "    train_loss = train_loss / len(data_loader)\n",
    "    train_acc = train_acc / len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module, train_loader: torch.utils.data.DataLoader, test_loader: torch.utils.data.DataLoader, optimizer: torch.optim.Optimizer,loss_fn: torch.nn.Module = nn.CrossEntropyLoss()):\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "        }\n",
    "    for epoch in range (6): #tqdm(range(epochs)):\n",
    "        \n",
    "        train_loss, train_acc = train_step(data_loader = training_loader,\n",
    "                                           model = model, loss_fn = loss_fn, optimizer = optimizer, accuracy_fn = accuracy_fn, device = device)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "        )\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "  total_time = end - start\n",
    "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "  return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, accuracy_fn, device: torch.device = device):\n",
    "  loss, acc = 0, 0\n",
    "  model.eval()\n",
    "  with torch.inference_mode():\n",
    "    for X, y in data_loader:\n",
    "      X, y = X.to(device), y.to(device).squeeze(1)\n",
    "      y_pred = model(X)\n",
    "\n",
    "      loss += loss_fn(y_pred, y)\n",
    "      acc += accuracy_fn(y_true = y, y_pred = y_pred.argmax(dim = 1))\n",
    "\n",
    "    loss /= len(data_loader)\n",
    "    acc /= len(data_loader)\n",
    "\n",
    "  return {\"model_name\": model.__class__.__name__, \n",
    "          \"model_loss\": loss.item(),\n",
    "          \"model_acc\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(results: Dict[str, List[float]]):\n",
    "    loss = torch.tensor(results['train_loss'])\n",
    "    test_loss = torch.tensor(results['test_loss'])\n",
    "\n",
    "    accuracy = results['train_acc']\n",
    "    test_accuracy = results['test_acc']\n",
    "\n",
    "    epochs = range(len(results['train_loss']))\n",
    " \n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, label='train_loss')\n",
    "    plt.plot(epochs, test_loss, label='test_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy, label='train_accuracy')\n",
    "    plt.plot(epochs, test_accuracy, label='test_accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_start_model = timer()\n",
    "\n",
    "for epochs in range(10):\n",
    "    train_step(data_loader=training_loader, model=model, loss_fn=loss_fn, optimizer=optimizer, accuracy_fn=accuracy_fn, device=device)\n",
    "\n",
    "train_time_end_model = timer()\n",
    "total_train_time_model = print_train_time(start=train_time_start_model, end=train_time_end_model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(model = model_1, data_loader = mitbih_test_dataloader, loss_fn = loss_fn, accuracy_fn = accuracy_fn, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(model_1_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
